{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from arithmetic_lm.model import load_model\n",
    "from arithmetic_lm.tokenizer import CharTokenizer\n",
    "from arithmetic_lm.constants import PLOTS_DIR, CHECKPOINTS_DIR\n",
    "from arithmetic_lm.utils import get_carry_str\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer()\n",
    "stop_token = tokenizer.encode(\"$\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_name = \"trans_dec_6layers_768embd_4head_randsp0.5_rev_ansloss\"\n",
    "ckpt_path = \"../checkpoints/addition-generalize-to-longer/trans_dec_6layers_768embd_4head_randsp0.5_rev_ansloss/step1000000-train_loss0.0002-val_loss0.0000.ckpt\"\n",
    "model, hparams = load_model(ckpt_path)\n",
    "model.to(\"mps\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hparams[\"extra_hparams\"][\"data_format\"])\n",
    "reverse_ops = hparams[\"extra_hparams\"][\"data_format\"][\"reverse_ops\"]\n",
    "reverse_ans = hparams[\"extra_hparams\"][\"data_format\"][\"reverse_ans\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_lens(\n",
    "    model,\n",
    "    model_name,\n",
    "    tokenizer,\n",
    "    prompt_idx: torch.Tensor,\n",
    "    true_ans: str,\n",
    "    max_new_tokens: int,\n",
    "    carry_str: str = None,\n",
    "    stop_token: str = \"$\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot unembedded logits from layers\n",
    "    \"\"\"\n",
    "\n",
    "    # shape: (seq_len, n_layers)\n",
    "    logits = []\n",
    "    # string, shape (seq_len, n_layers)\n",
    "    tokens = []\n",
    "\n",
    "    prompt = prompt_idx.clone()\n",
    "    pred_str = \"\"\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # get logits\n",
    "        logits_per_layer = get_layer_logits(model, prompt.unsqueeze(0))\n",
    "\n",
    "        # get top tokens and their logits\n",
    "        logits_step = []\n",
    "        tokens_step = []\n",
    "        for layer in range(model.n_layers):\n",
    "            top_token_idx = logits_per_layer[layer].argmax().item()\n",
    "            top_token: str = tokenizer.decode([top_token_idx])\n",
    "            top_logit: float = logits_per_layer[layer].max().item()\n",
    "            logits_step.append(top_logit)\n",
    "            tokens_step.append(top_token)\n",
    "        logits.append(logits_step)\n",
    "        tokens.append(tokens_step)\n",
    "\n",
    "        pred_str += top_token\n",
    "\n",
    "        if top_token == stop_token:\n",
    "            break\n",
    "\n",
    "        # add top token from last layer to prompt\n",
    "        # top token is the last top_token_idx left from the loop (i know bad practice)\n",
    "        prompt = torch.cat([prompt, torch.tensor([top_token_idx]).to(prompt.device)])\n",
    "\n",
    "    # transpose for plotting\n",
    "    logits = pd.DataFrame(logits).T\n",
    "    tokens = pd.DataFrame(tokens).T\n",
    "\n",
    "    prompt_str = tokenizer.decode(prompt_idx.tolist())\n",
    "\n",
    "    pred_dist = distance(pred_str, true_ans)\n",
    "    pred_correct = [a == b for a, b in zip(pred_str, true_ans)]\n",
    "\n",
    "    # plot small carry row on top, and heatmap of logits and add tokens to cells\n",
    "    # x axis is sequence position, y axis is layer\n",
    "    # on x axis add final predicted tokens\n",
    "    scale = 1.5\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(len(pred_str) / scale, model.n_layers / scale),\n",
    "    )\n",
    "\n",
    "    # plot main heatmap\n",
    "    sns.heatmap(logits, ax=ax, annot=tokens, fmt=\"\", cmap=\"viridis\")\n",
    "    ax.set_xlabel(\"Sequence ('c' means a carry was generated)\")\n",
    "    ax.set_ylabel(\"Layer\")\n",
    "    ax.set_title(\n",
    "        f\"LogitLens for {model_name}\\nPrompt: {prompt_str}\\nPrediction: {pred_str} (distance: {pred_dist})\\nTrue: {true_ans}\"\n",
    "    )\n",
    "\n",
    "    # set xticklabels to predicted tokens\n",
    "    ax.set_xticks(np.arange(len(pred_str)) + 0.5)\n",
    "    xlabels = [f\"{a}{'\\nc' if c in ('c', 'C') else \"\\n\"}\" for a, c in zip(pred_str, carry_str)]\n",
    "    for i, correct in enumerate(pred_correct):\n",
    "        if not correct:\n",
    "            xlabels[i] += f\"\\n{true_ans[i]}\"\n",
    "    if len(xlabels) < len(pred_str):\n",
    "        xlabels += pred_str[len(xlabels):]\n",
    "    ax.set_xticklabels(xlabels)\n",
    "\n",
    "    # set color of x axis labels to red & add correct pred if it's wrong\n",
    "    for i, correct in enumerate(pred_correct):\n",
    "        if not correct:\n",
    "            ax.get_xticklabels()[i].set_color(\"red\")\n",
    "            ax.get_xticklabels()[i].set_weight(\"bold\")\n",
    "\n",
    "    # put boxes around actually predicted token in each column\n",
    "    tokens_predicted = tokens.apply(lambda x: x == x.iloc[-1], axis=0)\n",
    "    for i, predicted in enumerate(tokens_predicted.values):\n",
    "        for j, is_predicted in enumerate(predicted):\n",
    "            is_true = tokens.iloc[i, j] == true_ans[j]\n",
    "            if is_predicted or is_true:\n",
    "                color = {True: \"black\", False: \"red\"}[(is_predicted and is_true) or is_true]\n",
    "                ax.add_patch(\n",
    "                    plt.Rectangle(\n",
    "                        (j, i),\n",
    "                        1,\n",
    "                        1,\n",
    "                        fill=False,\n",
    "                        edgecolor=color,\n",
    "                        clip_on=False,\n",
    "                        lw=3,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save plot\n",
    "    plot_path = PLOTS_DIR / \"gen_to_longer_rand_spaces\" / f\"{model_name}_logitlens.png\"\n",
    "    print(f\"Saving plot to {plot_path}\")\n",
    "    # plt.savefig(plot_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    return logits, tokens, pred_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
