# @package _global_

defaults:
  - override /tokenizer: char
  - override /sampling: default
  - override /data: add_1-9digit
  - override /training: default
  - override /wandb: default
  - override /model: ut_dec
  - _self_

data:
  format:
    pad: $
    reverse_ans: false
    encdec: false
    filler_tokens_prompt: 6
    filler_tokens_ans: 6

training:
  batch_size: 512
  lr: 0.0005
  max_iters: 20000
  limit_test_examples: 1000 # since test set is large
  devices: [0]

model:
  args:
    max_steps: 3
    n_embd: 192
    n_head: 2

wandb:
  project: "addition-1-9-digit-filler"
  run_name: ut_dec_${model.args.max_steps}steps_${model.args.n_embd}embd_${model.args.n_head}head_${data.format.filler_tokens_prompt}-${data.format.filler_tokens_ans}filler